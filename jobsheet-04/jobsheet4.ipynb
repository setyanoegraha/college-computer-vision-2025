{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e005e2ea",
   "metadata": {},
   "source": [
    "# Jobsheet 04: TEKNIK ANALISIS POSE & GEOMETRI TUBUH PADA GAMBAR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8e65d9",
   "metadata": {},
   "source": [
    "## Praktikum D1 - Inisialisasi Kamera dan Akuisisi Citra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "555cdf5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, time\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    raise RuntimeError(\"Kamera tidak bisa dibuka. Coba Index 1/2.\")\n",
    "\n",
    "frames, t0 = 0, time.time()\n",
    "while True:\n",
    "    ok, frame = cap.read()\n",
    "    if not ok: break\n",
    "    frames += 1\n",
    "    if time.time() - t0 >= 1:\n",
    "        cv2.setWindowTitle(\"Preview\", f\"Preview (FPS ~ {frames})\")\n",
    "        frames, t0 = 0, time.time()\n",
    "    cv2.imshow(\"Preview\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6c1569",
   "metadata": {},
   "source": [
    "## Praktikum D2 - Deteksi Pose dan Analisis Sudut Tubuh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fe6a8d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import cv2, numpy as np\n",
    "from cvzone.PoseModule import PoseDetector\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    raise RuntimeError(\"Kamera tidak bisa dibuka.\")\n",
    "\n",
    "detector = PoseDetector(staticMode=False, modelComplexity=1, \n",
    "                        enableSegmentation=False, detectionCon=0.5, trackCon=0.5)\n",
    "\n",
    "while True:\n",
    "    # Tangkah setiap frame dari webcam\n",
    "    success, img = cap.read()\n",
    "\n",
    "    # Temukan pose manusia dalam frame\n",
    "    img = detector.findPose(img)\n",
    "\n",
    "    # Temukan landmark, bounding box, dan pusat tubuh dalam frame\n",
    "    # Set draw=True untuk menggambar landmark dan bounding box pada gambar\n",
    "    lmList, bboxInfo = detector.findPosition(img, draw=True, bboxWithHands=False)\n",
    "\n",
    "    # Periksa apakah ada landmark tubuh yang terdeteksi\n",
    "    if lmList:\n",
    "        # Dapatkan pusat bounding box di sekitar tubuh\n",
    "        center = bboxInfo[\"center\"]\n",
    "\n",
    "        # Gambar lingkaran di pusat bounding box\n",
    "        cv2.circle(img, center, 5, (255, 0, 255), cv2.FILLED)\n",
    "\n",
    "        # Hitung jarak antara landmark 11 dan 15 dan gambarkan pada gambar\n",
    "        length, img, info = detector.findDistance(lmList[11][0:2],\n",
    "                                                  lmList[15][0:2],\n",
    "                                                  img=img,\n",
    "                                                  color=(255, 0, 0),\n",
    "                                                  scale=10)\n",
    "        \n",
    "        # Hitung sudut antara landmark 11, 13, dan 15 dan gambarkan pada gambar\n",
    "        angle, img = detector.findAngle(lmList[11][0:2],\n",
    "                                        lmList[13][0:2],\n",
    "                                        lmList[15][0:2],\n",
    "                                        img=img,\n",
    "                                        color=(0, 0, 255),\n",
    "                                        scale=10)\n",
    "        \n",
    "        # Periksa apakah sudut mendekati 50 derajat dengan offset 10\n",
    "        isCloseAngle50 = detector.angleCheck(myAngle=angle,\n",
    "                                             targetAngle=50,\n",
    "                                             offset=10)\n",
    "        \n",
    "        # Cetak hasil pemeriksaan sudut\n",
    "        print(isCloseAngle50)\n",
    "\n",
    "    cv2.imshow(\"Pose + Angle \", img) # type: ignore\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca455f78",
   "metadata": {},
   "source": [
    "## Praktikum D3 - Deteksi Wajah dan Analisis Kedipan Mata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bdcd63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, numpy as np\n",
    "from cvzone.FaceMeshModule import FaceMeshDetector\n",
    "\n",
    "# Indeks mata kiri (contoh): vertikal (159, 145), horizontal (33, 133)\n",
    "L_TOP, L_BOTTOM, L_LEFT, L_RIGHT = 159, 145, 33, 133\n",
    "\n",
    "def dist(p1, p2): return np.linalg.norm(np.array(p1) - np.array(p2))\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    raise RuntimeError(\"Kamera tidak bisa dibuka.\")\n",
    "\n",
    "# Inisialisasi objek FaceMeshDetector\n",
    "# staticMode: Jika True, deteksi hanya terjadi sekali; jika False, setiap frame\n",
    "# maxFaces: Jumlah maksimum wajah yang dideteksi\n",
    "# minDetectionCon: Ambang kepercayaan deteksi minimum\n",
    "# minTrackCon: Ambang kepercayaan pelacakan minimum\n",
    "detector = FaceMeshDetector(staticMode=False, maxFaces=1, minDetectionCon=0.5, minTrackCon=0.5)\n",
    "\n",
    "# Variabel untuk menghitung kedipan sederhana\n",
    "blink_count = 0\n",
    "closed_frames = 0\n",
    "CLOSED_FRAMES_THRESHOLD = 3  # jumlah frame berturut-turut untuk dianggap kedipan\n",
    "EYE_AR_THRESHOLD = 0.20     # ambang Eye Aspect Ratio (EAR) untuk menilai mata tertutup\n",
    "is_closed = False\n",
    "\n",
    "while True:\n",
    "    ok, img = cap.read()\n",
    "    if not ok: break\n",
    "    img, faces = detector.findFaceMesh(img, draw=True)\n",
    "    if faces:\n",
    "        face = faces[0] # list of 468 (x, y)\n",
    "        v = dist(face[L_TOP], face[L_BOTTOM])\n",
    "        h = dist(face[L_LEFT], face[L_RIGHT])\n",
    "        ear = v / (h + 1e-8)\n",
    "        cv2.putText(img, f\"EAR(L): {ear:.3f}\", (20, 40),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 255), 2)\n",
    "        \n",
    "        # Contoh ambang kedipan sederhana dan logika counter:\n",
    "        # jika EAR < EYE_AR_THRESHOLD selama CLOSED_FRAMES_THRESHOLD frame -> hitung kedipan\n",
    "        if ear < EYE_AR_THRESHOLD:\n",
    "            closed_frames += 1\n",
    "            if closed_frames >= CLOSED_FRAMES_THRESHOLD and not is_closed:\n",
    "                blink_count += 1\n",
    "                is_closed = True\n",
    "        else:\n",
    "            closed_frames = 0\n",
    "            is_closed = False\n",
    "\n",
    "        # Tampilkan jumlah kedipan pada frame\n",
    "        cv2.putText(img, f\"Blink: {blink_count}\", (20, 70),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "        \n",
    "    cv2.imshow(\"FaceMesh + EAR\", img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca77b74",
   "metadata": {},
   "source": [
    "## Praktikum D4 - Deteksi Tangan dan Penghitungan Jumlah Jari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "262069f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\A_College\\Semester3\\Visi_Komputer\\college-computer-vision-2025\\jobsheet-04\\.venv\\Lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from cvzone.HandTrackingModule import HandDetector\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    raise RuntimeError(\"Kamera tidak bisa dibuka.\")\n",
    "\n",
    "detector = HandDetector(staticMode=False, maxHands=1, modelComplexity=1,\n",
    "                        detectionCon=0.5, minTrackCon=0.5)\n",
    "\n",
    "while True:\n",
    "    ok, img = cap.read()\n",
    "    if not ok: break\n",
    "    hands, img = detector.findHands(img, draw=True, flipType=True) # flipType untuk mirror UI\n",
    "    if hands:\n",
    "        hand = hands[0] # dict berisi \"lmList\", \"bbox\", dll.\n",
    "        fingers = detector.fingersUp(hand) # list panjang 5 berisi 0/1\n",
    "        count = sum(fingers)\n",
    "        cv2.putText(img, f\"Fingers: {count} {fingers}\", (20, 40),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "        \n",
    "    cv2.imshow(\"Hands + Fingers\", img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0130ea9d",
   "metadata": {},
   "source": [
    "## Praktikum D5 - Pengenalan Gestur Tangan (Hand GestureRecognition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "975f1575",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\A_College\\Semester3\\Visi_Komputer\\college-computer-vision-2025\\jobsheet-04\\.venv\\Lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    }
   ],
   "source": [
    "import cv2, numpy as np\n",
    "from cvzone.HandTrackingModule import HandDetector\n",
    "\n",
    "def dist(a,b): return np.linalg.norm(np.array(a)-np.array(b))\n",
    "\n",
    "def classify_gesture(hand):\n",
    "    # hand[\"lmList\"] berisi 21 titik (x,y,z) dalam piksel saat flipType=True\n",
    "    lm = hand[\"lmList\"]\n",
    "    wrist = np.array(lm[0][:2])\n",
    "    thump_tip = np.array(lm[4][:2])\n",
    "    index_tip = np.array(lm[8][:2])\n",
    "    middle_tip = np.array(lm[12][:2])\n",
    "    ring_tip = np.array(lm[16][:2])\n",
    "    pinky_tip = np.array(lm[20][:2])\n",
    "    # Heuristik jarak relatif\n",
    "    r_mean = np.mean([dist(index_tip, wrist), dist(middle_tip, wrist),\n",
    "                      dist(ring_tip, wrist), dist(pinky_tip, wrist), dist(thump_tip, wrist)])\n",
    "    # Aturan:\n",
    "    if dist(thump_tip, index_tip) < 35: return \"OK\"\n",
    "    # Thumbs up: ibu jari tinggi (y kecil), dan jauh dari wrist\n",
    "    if (thump_tip[1] < wrist[1]-40) and (dist(thump_tip, wrist) > 0.8*dist(index_tip, wrist)):\n",
    "        return \"THUMBS_UP\"\n",
    "    if r_mean < 120: return \"ROCK\"\n",
    "    if r_mean > 200: return \"PAPER\"\n",
    "    if dist(index_tip, wrist) > 180 and dist(middle_tip, wrist) > 180 and \\\n",
    "    dist(ring_tip, wrist) < 160 and dist(pinky_tip, wrist) < 160:\n",
    "        return \"SCISSORS\"\n",
    "    return \"UNKNOWN\"\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    raise RuntimeError(\"Kamera tidak bisa dibuka.\")\n",
    "\n",
    "detector = HandDetector(staticMode=False, maxHands=1, modelComplexity=1,\n",
    "                        detectionCon=0.5, minTrackCon=0.5)\n",
    "\n",
    "while True:\n",
    "    ok, img, = cap.read()\n",
    "    if not ok: break\n",
    "    hands, img = detector.findHands(img, draw=True, flipType=True)\n",
    "    if hands:\n",
    "        label = classify_gesture(hands[0])\n",
    "        cv2.putText(img, f\"Gesture: {label}\", (20, 40),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 255), 2)\n",
    "        \n",
    "    cv2.imshow(\"Hand Gesture (cvzone)\", img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44467e4a",
   "metadata": {},
   "source": [
    "## Praktikum D6 - Analisis Gerakan Tubuh dan Penghitung Aktivitas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59765dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\A_College\\Semester3\\Visi_Komputer\\college-computer-vision-2025\\jobsheet-04\\.venv\\Lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    }
   ],
   "source": [
    "import cv2, numpy as np\n",
    "from collections import deque\n",
    "from cvzone.PoseModule import PoseDetector\n",
    "\n",
    "MODE = \"squat\"                  # tekan 'm' untuk toggle ke \"pushup\"\n",
    "KNEE_DOWN, KNEE_UP = 80, 160    # ambang squat (deg)\n",
    "DOWN_R, UP_R = 0.85, 1.00       # ambang push-up (rasio)\n",
    "SAMPLE_OK = 4                   # minimal frame konsistem sebelum ganti state\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    raise RuntimeError(\"Kamera tidak bisa dibuka.\")\n",
    "\n",
    "detector = PoseDetector(staticMode=False, modelComplexity=1,\n",
    "                        enableSegmentation=False, detectionCon=0.5, trackCon=0.5)\n",
    "\n",
    "count, state = 0, \"up\"\n",
    "debounce = deque(maxlen=6)\n",
    "\n",
    "def ratio_pushup(lm):\n",
    "    # gunakan kiri: 11=shoulderL, 15=wristL, 23=hipL\n",
    "    sh = np.array(lm[11][1:3])\n",
    "    wr = np.array(lm[15][1:3])\n",
    "    hp = np.array(lm[23][1:3])\n",
    "    return np.linalg.norm(sh - wr) / (np.linalg.norm(sh - hp) + 1e-8)\n",
    "\n",
    "while True:\n",
    "    ok, img = cap.read()\n",
    "    if not ok: break\n",
    "    img = detector.findPose(img, draw=True)\n",
    "    lmList, _ = detector.findPosition(img, draw=False) # [(id, x, y, z, vis), ...]\n",
    "    flag = None\n",
    "\n",
    "    if lmList:\n",
    "        if MODE == \"squat\":\n",
    "            # rata-rata sudut lutut kiri & kanan\n",
    "            # angL, _ = detector.findAngle(img, 23, 25, 27, draw=False)\n",
    "            # angR, _ = detector.findAngle(img, 24, 26, 28, draw=False)\n",
    "\n",
    "\n",
    "            angL, img = detector.findAngle(lmList[23][0:2],\n",
    "                                           lmList[25][0:2],\n",
    "                                           lmList[27][0:2],\n",
    "                                           img=img,\n",
    "                                           color=(0, 0, 255),\n",
    "                                           scale=10)\n",
    "            \n",
    "            angR, img = detector.findAngle(lmList[24][0:2],\n",
    "                                           lmList[26][0:2],\n",
    "                                           lmList[28][0:2],\n",
    "                                           img=img,\n",
    "                                           color=(0, 255, 0),\n",
    "                                           scale=10)\n",
    "            \n",
    "            ang = (angL + angR) / 2.0\n",
    "            if ang < KNEE_DOWN: flag = \"down\"\n",
    "            elif ang > KNEE_UP: flag = \"up\"\n",
    "            cv2.putText(img, f\"Knee: {ang:5.1f}\", (20, 70), # type: ignore\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2) # type: ignore\n",
    "        else:\n",
    "            # push-up: rasio (shoulder-wrist)/(shoulder-hip)\n",
    "            r = ratio_pushup(lmList)\n",
    "            if r < DOWN_R: flag = \"down\"\n",
    "            elif r > UP_R: flag = \"up\"\n",
    "            cv2.putText(img, f\"Ratio: {r:4.2f}\", (20, 70),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2)\n",
    "            \n",
    "        debounce.append(flag)\n",
    "        if debounce.count(\"down\") >= SAMPLE_OK and state == \"up\":\n",
    "            state = \"down\"\n",
    "        if debounce.count(\"up\") >= SAMPLE_OK and state == \"down\":\n",
    "            state = \"up\"; count += 1\n",
    "\n",
    "    cv2.putText(img, f\"Mode: {MODE.upper()} Count: {count}\", (20, 40), # type: ignore\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 255, 255), 2) # type: ignore\n",
    "    cv2.putText(img, f\"State: {state}\", (20, 100),  # type: ignore\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2) # type: ignore\n",
    "    \n",
    "    cv2.imshow(\"Pose Counter\", img) # type: ignore\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('q'): break\n",
    "    if key == ord('m'): MODE = \"pushup\" if MODE == \"squat\" else \"squat\"\n",
    "                  \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
